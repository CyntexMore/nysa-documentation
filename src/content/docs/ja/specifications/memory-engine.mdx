---
title: メモリエンジン（nmgine）仕様
description: Nysaのメモリエンジン（nmgine）の仕様です。
---

import { Steps, Card } from '@astrojs/starlight/components';

メモリエンジン（nmgine）は、セッション間での会話コンテキストを維持する役割を担います。重要な事実、ユーザーの嗜好、会話履歴を保存します。このコンポーネントは、Nysaが時間とともに改善される一貫性のあるパーソナライズされた会話を可能にするために重要です。

Nysaの本質的にモジュール化されたアーキテクチャにより、nmgineは他のアプリケーションのメモリエンジンとしても使用可能です。`@nysa-daemon/nmgine` npmパッケージとして公開されるべきです。

## 問題提起

nmgineがなければ、Nysaは時間とともに進化しない固定されたパーソナリティを持ち、セッション間で何も覚えられないため、一般的なAIチャットボットになってしまいます。主な課題は以下の通りです：

* **コンテキストの破壊を防ぐ**：LLMには限られたコンテキストウィンドウがあります（例：[Claude Opus 4.5](https://openrouter.ai/anthropic/claude-opus-4.5)では200kトークン）。すべてを単純に圧縮すると重要な詳細が失われます。何も圧縮しないと、モデルは一般的に50kトークンを超えると知能が低下し始め、会話が破綻するため、重要な詳細が失われます。
* **重要性の重み付け**：すべての記憶が等しいわけではありません。「ユーザーの名前はJane Doeです」は永遠に保持されるべきです。「ユーザーは昨日ピザを注文した」はすぐに消えても構いません。
* **時間とともに薄れる記憶**：人間は詳細を忘れますが、要点は覚えています。1週間前の記憶は、昨日の記憶よりも大幅に短く曖昧であるべきです。

これら3つをバランスさせるソリューションが必要です：トークン制限内に収まり、重要なことを保持し、自然な記憶の減衰を模倣すること。

## アーキテクチャ

## 記憶の保存

nmgineは記憶を保存する際に6つの主要ステップに従います：

<Steps>
1. すべての入力をリッスンする。
2. 現在のセッションのチャット履歴を保存する。
3. nmgineは`M`分ごとにコンテキスト圧縮を実行します。その際、2つのプロンプトを実行します：1）セッションの履歴を要約するもの、2）要約から保存に値するものを評価するもの。
4. モデルは、公開されたツール（適切な検証レイヤー付き；モデルにSQLコマンドを直接実行させない）を介してデータベースに記憶を保存し、重要性を選択できるようにします。
5. 記憶を効率的にインデックス化する。
6. 時間とともに記憶の整合性を劣化させ、最終的にエントリを自動削除します。重要性の高い記憶は整合性劣化に対する耐性が高くなります。
</Steps>

<br/>
<Card title="整合性劣化" icon="information">
    この文脈での整合性劣化とは、インデックス化された記憶をモデルが評価し、作成日と重要性に基づいて（強制的な要約に基づいて`content`をより曖昧にして）短くすることを意味します。重要性が高いほど整合性劣化に対する耐性が高く、重要性の低い記憶と同じ程度に劣化するまでにより多くの時間が必要です。

    記憶の劣化は`D`日ごとに発生します。`D`はユーザー定義です。劣化はハイブリッドアプローチで行われます：1）年齢と重要性に基づく自動劣化、2）`refreshCount`が`T`閾値を超えた場合、モデルを呼び出して手動で劣化と評価を行う。

    レベル0は完全なテキスト（新鮮）です。レベル1は軽く正規化されたもの（表現を整えたもの）です。レベル2は要約です。レベル3は要約の要約です。レベル4はキーワードです。レベル5は空です（空の記憶は次の劣化サイクル中に自動的に削除されます）。

    `refreshCount`の高い記憶は、より低いレベルにアップグレードされることがあります（例：レベル2 → レベル1）。これにより、有用な記憶が不当に損なわれるのを防ぎます。
</Card>
<br/>

## 記憶の検索

そして記憶を返す際にはさらに4つのステップに従います：

<Steps>
1. キーワードを含むツール呼び出しを受け取る。
2. ベクトル化データベースからのTop-K結果に基づいて、最初の`N`個の記憶をモデルに表示する。
3. より小さいモデルがTop-K結果を関連性でランク付けする。
4. 記憶全体を取得する。
</Steps>

検索のバイアスは`(relevance * 0.8) + (recency * 0.2)`です。

## ルール

### 記憶の検索

このルールはシステムプロンプトで記憶検索時に適用されるべきです：

1. 記憶に`userId`配列が紐付いている場合、それは存在するIDのユーザーに完全に属していることを意味します。他の人の個人的な嗜好やデータとして扱わないでください。

### 圧縮ルール

これらは2パス圧縮の2番目のプロンプトでシステムプロンプトとして適用されるべき一般的なルールです：

1. 些細な詳細をすべて保存しないでください。人間の脳が情報をどのように保存するかを考えてください。
2. モデルが情報を保存する際、（ユーザーごとに）矛盾するデータポイントをチェックし、古いものを更新または上書きする必要があります。これはモデルが記憶検索プロセスを実行することで発生します。

### 劣化ルール

これらのルールは記憶劣化プロセス中に適用されるべきです：

1. 24時間以上経過した記憶を評価し、必要に応じて`content`を上書きし、`integrityLevel`も更新します。
2. `importance >= 8`の場合、記憶は意味記憶（Semantic）または長期的なエピソード記憶（Episodic）でなければなりません。`importance <= 3`の場合、自動期限切れ上限（`D`日を超えて存続できない）が適用されます。

## 設計上の決定

### 2パス圧縮（要約 → 評価）

1回のモデル呼び出しの代わりに2回の別々のモデル呼び出しを使用します。

なぜ2パスなのか？

* 第1パス（要約）：すべてを中立的に捉えます。タイムスタンプとトピックを含む構造化された出力を提供します。
* 第2パス（評価）：新しいコンテキストで保存に値するものを決定します。

代替アプローチ（シングルパス）はより速いでしょうが、モデルは両方のタスクを同時に行おうとする際にニュアンスを見逃す可能性があります。

トレードオフはAPI呼び出しが2倍になることですが、テストでは記憶の質が大幅に向上します。

# 技術仕様

## データモデル

### Memoryオブジェクト

```typescript
interface Memory {
  id: number; // 記憶のインデックス
  userId?: string[]; // ソーシャルプラットフォームのユーザーID
  shortName: string; // "ユーザーの好きな食べ物"
  type: MemoryType; // EpisodicまたはSemantic
  content: string; // "Janeは特にタイカレーが好きなベジタリアンです。"
  importance: number; // 0-10のスコア、モデルが割り当てる
  confidence: number; // 0-10のスコア、モデルが割り当てる；記憶への確信度を定義
  createdAt: Date;
  lastAccessedAt: Date;
  integrityLevel: number; // 0（新鮮）- 5（大幅に劣化）
  originalLength: number; // 圧縮率を追跡
  refreshCount: number; // 記憶が取得された回数
}
```

### Memory Type
```typescript
enum MemoryType {
  Episodic,
  Semantic
}
```

## ツール

### `suggests_category(...)`

#### パラメータ

* `name: string`: カテゴリの名前

#### 説明

カテゴリ`name`の作成を提案します。適切なカテゴリがすでに存在するかどうかをチェックするプロンプトを実行します（これは比較的保守的であるべきです）。

#### 内部で使用されるモデル

* `MEMORY_EVALUATION_MODEL`

### `retrieve_memory(...)`

#### パラメータ

* `keyword: string`: 返す記憶のキーワード

#### 説明

記憶データベースからの最初の`N`個（再ランキング済み）のTop-K結果を返します。

#### 内部で使用されるモデル

* `MEMORY_RETRIEVAL_RANKING_MODEL`

# モデル

|モデル|役割|推奨|
|:----|:--:|-------------:|
|`MEMORY_EVALUATION_MODEL`|保存する記憶を評価する。|賢く、適正価格のモデル。|
|`MEMORY_COMPRESSION_MODEL`|記憶を要約・圧縮する。|安く、高速なモデル。|
|`MEMORY_INTEGRITY_DEGRADATION_MODEL`|記憶をどのように劣化させるかを決定する。|`MEMORY_EVALUATION_MODEL`と同じモデルを推奨|
|`MEMORY_RETRIEVAL_RANKING_MODEL`|記憶検索のために返されたTop-K結果をランク付けする。|小さなリランカー。|

これらは環境変数で設定できます。変数が設定されていない場合、[`AI_SDK_DEFAULT_MODEL`](/specifications/ai-sdk#configuration)が使用されます。
